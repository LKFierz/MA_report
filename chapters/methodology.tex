\chapter{Methodology}
\label{sec:methodology}

As mentioned above the endeavour of this thesis was to put together a front to back landing procedure utilizing an existing vision based landing site detection pipeline and an autonomous framework. In order to do this, all individual software instances needed to be ready in order to combine them and achieve autonomous landing in unknown terrain.

\section{Stereo Camera Depth Perception} \label{sec:StereoDepth}

The autonomous framework\citep{Autonomy} allows us to fly independent missions at cruise altitude of 100m+. The structure from motion approach captures 3D information during traversal as its adaptive baseline allows it to perceive high quality depth information also at such high altitudes. This information can be used by LSD in order to detect landing sites during mission. 

At low altitudes SFM works as well but surrounded with obstacles, the need for lateral motion poses significant risk. This is because the drone does not retain any hazard information due to the limitations of computational complexity present for mars flights. 

In the following a qualitative analysis of the comparison of SFM and stereo camera depth is layed out:

\subsection{Lateral Motion}

As already mentioned above the need for lateral motion in itself is an undesirable necessity for a rotorcraft in unknown terrain. 

In this setup the structure from motion approach is based on a keyframe buffer which needs to be filled with image-pose pairs at different horizontal positions in order to start acquiring depth information. The current setting in the implementation \citet{SFM} uses 6 keyframes. Therefore for a single point cloud it is necessary to move laterally 6 times in order to start perceiving depth. 

\subsection{Software vs Hardware Depth Perception}

Structure from Motion, being a software node that relies on camera poses supplied by a state estimator, is by design subject to inaccuracies. A depth node based on a stereo camera on the other hand works with a fixed rigid baseline between the camera views. Thus for low altitude flights that bear the danger of collision, a more robust hardware approach is preferred.

\subsection{DEM Conversion}

As described in \cref{subsubsec:setup:aggregation} the multi-resolution DEM used for depth aggregation in LSD is based on Optimal Mixture of Gaussian cells and thus converges over time. 

According to \cref{subsubsec:setup:haz_seg} the landing sites chosen are likely on terrain with low uncertainty. Because of this landing sites are more likely to be detected and have in general a better quality when the terrain perceived has been viewed.

When a landing site has been selected we need to make sure that the landing site is actually correctly detected and of good quality. For this we would like to (re-)detect landing sites on rather converged terrain. Structure from Motion needs constant lateral motion for this. A stereo camera depth node simply hovers in place for any given amount of time.

\subsubsection{Efficiency}

All in all the stereo camera setup allows us to perceive a landing site at course altitude and after having traversed horizontally to that location, we can simply descent to a stereo camera friendly altitude for the verification. Compared to repeated lateral coverage of the area in question this is a huge increase in efficiency.

\subsection{Theoretical Analysis}

When it comes to depth perception the obvious drawback of a stereo camera is its limited baseline. It only perceives depth accurately for objects within a certain proximity to the lense. 

Assuming a perfectly calibrated and rectified camera there is still always an inaccuracy in the depth estimation arising from the disparity error.

From a given disparity estimate the depth error is derived as follows:

\begin{equation}\label{eq:depth_from_disp}
    z = \frac{f \cdot b}{d}
\end{equation}

Where b is the z is the depth estimate, b is the baseline, f is the focal length and d is the disparity value.

Taking the derivative of z w.r.t. d we get

\begin{equation}
    \frac{\partial z}{\partial d} = - \frac{f  \cdot b}{z^2}
\end{equation}

And substituting (\cref{eq:depth_from_disp}) we get:

\begin{equation}
    {\partial z} = \frac{z^2}{f  \cdot b}\partial d
\end{equation}

Where the sign was left away as for our application there lies equal danger in a point being perceived too close and too far away.

For the maximum altitude given a maximum allowable depth error this yields:

\begin{equation}
    z_{\text{max}} = \sqrt{\frac{\Delta z_{\text{max}} \cdot b \cdot f}{\Delta d}}
\end{equation}

Where $\Delta z$ is the depth error and $\Delta d$ the disparity error.

The stereo camera mounted on the drone in JPL's aerial vehicle lab had a baseline of about 10cm and a focal length of 256.

With these properties and estimating a subpixel precision disparity error of 0.25 pixels 




\subsection{Qualitative Practical Analysis}



\section{Landing Site Properties}\label{sec:LSproperties}

Before this work the output of the landing site dection algorithm was merely the location of a found landing site. However as described in \cref{subsubsec:setup:haz_seg} the landing site detection algorithms segments hazards based on roughness and slope. Subsequently it considers the size of a landing site as well as the uncertainty associated with a certain selected location. 

Simply outputting the location of a landing site is therefore a waste of information when so many characteristics are at hand to make an informed selection. 

I decided on the following properties to be output alongside the site's location:

\begin{itemize}
    \item Uncertainty
    \item Roughness
    \item Size
    \item Obstacle Altitude
\end{itemize}
The final landing site detection output is a custom landing site ROS message containing the above mentioned characteristics of the detected spot.

\subsection{Roughness}

The roughness value the exact value already used for the hazard segmentation step in the landing site detection. 

\subsection{Uncertainty}

The uncertainty value is also a product of the landing site detection algorithm. It denotes the averaged uncertainty across the area around a given landing site. The uncertainty of a single map cell denotes the stereo depth error estimates merged over time.

\subsection{Size}

To determine the size of a landing site, the landing site detection algorithm performs a distance transform on the created landing site map in order to find the closest non-landing site for any found landing site. This returns the radius of the largest valid landing circle around a landing site. Calculating the physical value, the metric radius is returned as the size of a landing site.

\subsection{Obstalce Altitude}

The obstacle altitude was newly introduced in this work. It defines the currently highest point of the aggregated DEM's highest resolution layer. As no actual object detection is performed and no hazard information is retained in this visual pipeline, this value serves the autonomy as an indication of the obstacles heights to avoid in the vicinity of a certain landing site. More on this in \cref{subsubsec:LandingSiteHeuristic}.



\section{Autonomous Landing Procedure}

With the enhanced structure of the LSD output and having implemented a stereo camera as a low altitude alternative to SFM, the main contribution of this work could be faced.

\subsection{Landing Site Handling}

As shown in \cref{sec:setup:autonomy} the autonomy is structured in a hierarchical and modular way. The current state of the state machine determines the specific task to be executed in that state's execution node. As the landing sites are constantly received alongside the mission tasks performed, they have to be processed in a separate thread. This is handled by a landing site manager (LSM) singleton class which ranks the landing sites according to a loss function and stores them in a heap buffer.

\subsubsection{Landing Site Heuristic}\label{subsubsec:LandingSiteHeuristic}

As mentioned in \cref{sec:LSproperties} the autonomy receives landing sites with the following properties:

\begin{itemize}
    \item Position
    \item Roughness
    \item Uncertainty
    \item Size
    \item Obstacle Altitude
\end{itemize}

From these properties the characteristics that comprise the final heuristic are:

\begin{itemize}
    \item Current Distance to Drone
    \item Roughness
    \item Uncertainty
    \item Size
    \item Verification Altitude
\end{itemize}

\textbf{Current Distance to Drone}

Each iteration the current distance to the drone's position is calculate for each retained landing site. The distance is then normalized by dividing it by the cruise altitude which is 100m. Note that in practice landing sites fell off when farther away than 100m which yields a valid normalization. %TODO
\clearpage

\textbf{Roughness}
%TODO

The roughness property is the unaltered roughness value received from LSD. It is already normalized and enters the loss function as it is. 

\textbf{Uncertainty}

The same holds for the uncertainty. It is already normalized by design and enters the loss function unaltered.

\textbf{Size}

Analogous to the roughness and uncertainty properties the size comes from the landing site detection directly. However unlike the two preceeding properties it is not normalized but simply denotes the metric radius of the largest circle fitted around a given landing site. This is achieved in LSD by performing a distance transform on the landing site image.

In order to normalize this value the maximum landing site size is retained and each landing site's size is divided by it in order to achieve the normalized size indication.

\textbf{Verification Altitude}

A site's verificaiton altitude is the smallest vertical distance between the drone and the landing site at which that site was (re-) detected. Similar to the uncertainty metric the verification altitude indicates how certain we can be about a detected landing site as spots detected at lower flight altitudes are more likely correct due the reduced depth error. 

\subsubsection{Landing Site Input Processing}
The landing site manager receives the landing sites from the ROS connector within the autonomy. 

\subsubsection{}

