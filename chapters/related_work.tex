\chapter{Related Work}
\label{sec:relwork}

% TODO: Split this into three parts, one being general Rotorcraft landing, one being specific autonomy frameworks and one being stereo

Autonomous safe landing is perhaps the most important part of a rotorcraft's mission. It comes, therefore, as no surprise that tremendous amounts of work have been accomplished to achieve this crucial feature. 

Camera sensors are highly advantageous for navigation due to their lightweight nature and the extensive research dedicated to their development over the years. Their minimal weight makes them particularly suitable for applications where payload capacity is a critical concern, such as rotorcraft Mars missions. Decades of intensive research have culminated in highly sophisticated algorithms and methodologies that leverage the rich data captured by visual sensors and enable the daunting task of autonomous landing.

\section{Landing based on Visual Markers}
\citep{Saripalli2002VisionBasedLanding,Falanga2017QuadrotorLanding} and \citep{Mu2023VisionBasedLanding} use artificial landing markers as indications of valid landing sites. While \citep{Saripalli2002VisionBasedLanding} and \citep{Mu2023VisionBasedLanding} use stationary markings, \citep{Falanga2017QuadrotorLanding} enabled a rotorcraft to land on a moving target. Though useful in urban environments, these approaches are not applicable to uncharted terrain as found on Mars.

\section{Homography-based Autonomous Landing}

\citep{Bosch2006AutonomousDetection,Brockers2011AutonomousLanding,Desaraju2015VisionBased} and \citep{Brockers2014TowardsAutonomous} pursue implementations based on homography assumptions. This is impossible in our setup as we cannot assume homographic conditions on Mars' rough terrain. %TODO What exactly did they do?

\section{Landing Mechanisms based on Ranger Sensors}
A very handy tool for the creation of elevation maps to segment landing sites on are range sensors like Lidar as \citep{Trawny2015FlightTesting, Luna2017Evaluation, Johnson2002LidarBased} and \citep{Scherer2012AutonomousLanding} show. 

As for our purposes, a rotorcraft has to fly on Mars' 1\% air density. However, weight is a limiting constraint, rendering the Lidar sensor a suboptimal choice.

\section{Mars Lander Approach}
For the Mars Mission's lander, NASA has used a vision-based strategy using a predefined map of Mars' surface and a downwards-facing monocular camera to orient the lander in the predefined map\citep{Johnson2020Mars2020}. However, rotorcrafts need to consider much smaller hazards compared to a lander. At 25 cm/pixel for images and 1 m/pixel for the DEM, the available Mars footage from the HiRISE camera on the Mars Reconnaissance Orbiter is not sufficient in resolution to supply prior information to the landing process of a UAV. Rover images and Ingenuity footage could be used. However, the usage of this data would limit possible flight areas significantly.


\section{Elevation Mapping Approaches}
\citep{Johnson2005VisionGuided} uses a similar approach as the one used by LORNA. Compared to LORNA's Landing Site Detection (\citep{LSD1,LSD2}), however, a non-robot-centric DEM is used. 

Modern approaches like \citep{Fankhauser2014RobotCentric, Forster2015Continuous} and \citep{Daftry2018Robust} use a 2.5D terrain representation similar to the setup used in this project.

\section{Learning based Methods}
Other novel approaches use learning-based methods as did \citep{Neves2024Multimodal, Abdollahzadeh2022SafeLandingZones} and \citep{TovanchePicon2024RealTimeSafeValidation}. Though certainly promising regarding accuracy and, in the long run, definitely a pathway to consider, learning-based methods come with significant costs in the context of the task at hand. First of all, considering the limitations present in Mars missions, the probable additional computational overhead from learning-based methods can not be neglected. Furthermore, neural network-based solutions give up simplicity and interpretability for the benefit of precision. This is not to be underestimated in a hostile environment such as Mars' rough terrain, where perfect accuracy is required. Additionally, learning-based methods require substantial training data, which is not available in large quantities in the context of autonomous UAV landing. Especially when the training data needs to come from another planet. Lastly, missions flown on Mars pose unique challenges compared to conventional flights. Such specific knowledge can be leveraged in traditional methods to tailor an efficient procedure to the needs at hand. An example of this could be the knowledge about Mars' terrain monotony and the often present lack of texture.