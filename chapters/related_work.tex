\chapter{Related Work}
\label{sec:relwork}

Autonomous safe landing is perhaps the most important part of a rotorcraft's mission. It comes therefore as no surprise, that tremendous amounts of work have been accomplished in the pursuit of achieving this crucial feat. 

\section{Artificial Landing Markers}

Utilizing vision based approaches is also not a new idea. \citep{Saripalli2002VisionBasedLanding,Falanga2017QuadrotorLanding} and \citep{Mu2023VisionBasedLanding} use artificial landing markers as indications of valid landing sites. 

\citep{Bosch2006AutonomousDetection,Brockers2011AutonomousLanding,Desaraju2015VisionBased} and \citep{Brockers2014TowardsAutonomous} pursue implementations based on homography assumptions. This is not possible in our setup as we cannot assume homographic conditions on Mars' rough terrain.

A very handy tool for the creation of depth maps to segment landing sites on are range sensors like Lidar as \citep{Trawny2015FlightTesting, Luna2017Evaluation, Johnson2002LidarBased} and \citep{Scherer2012AutonomousLanding} show. As a rotorcraft has to fly on Mars' 1\% air density however, weight is a limiting constraint rendering Lidar sensor a suboptimal choice.

For the Mars Mission's lander NASA has used a vision based strategy using a predefined map of Mars' surface and a downwards facing monocular camera to orient the lander in the predefined map\citep{Johnson2020Mars2020}. When compared to a lander however, rotorcrafts need to consider much smaller hazards. The available HiRISE satellite images are not sufficient in resolution to supply such prior information to the landing process of a UAV. Rover images could be used as well as Ingenuity's footage however the usage of this data would limit possible flight areas significantly.

\citep{Johnson2005VisionGuided} use a similar approach as the one used by LORNA. Compared to LORNA's Landing Site Detection \citep{LSD1,LSD2} however, a non-robot-centric DEM is used. The advantage of LORNA's approach is the implicit drift handling by considering the robot-centered terrain map.

Modern approaches like \citep{Fankhauser2014RobotCentric, Forster2015Continuous} and \citep{Daftry2018Robust} use a 2.5D terrain representation similar to the setup used in this project.

Other novel approaches use learning based methods as did \citep{Neves2024Multimodal, Abdollahzadeh2022SafeLandingZones} and \citep{TovanchePicon2024RealTimeSafeValidation}. Though certainly promising regarding accuracy and in the long run definitely a pathway to consider, learning based methods come with significant costs in the context of the task at hand. First of all considering the limitations present in Mars missions, the probable additional computational overhead from learning based methods can not be neglected. Furthermore, neural network based solutions give up simplicity and interpretablity for the benefit of precision. This is not to be underestimated in a tricky environment such as Mars terrain. Additionally, learning based methods require substantial training data which, in the context of autonomous UAV landing, is not available in large quantities. Lastly complex and specific missions flown on Mars pose their unique challenges. Niche information about these problems can be fused into conventional methods in the form of prior assumptions and constraints.

% 